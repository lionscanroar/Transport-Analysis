{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28c5bbcc",
   "metadata": {},
   "source": [
    "# Data Science Group Project\n",
    "### Group 51\n",
    "Thuseevan Nareshkumar 46328785 <br>\n",
    "Ryan Lam 45951292<br>\n",
    "Md Fahad Rahman 45728836\n",
    "### Name and Student number \n",
    "add you name here then remove this "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b723a1",
   "metadata": {},
   "source": [
    "# Introduction\n",
    " Transport Performance and Analytics (TPA) is a Center of Excellence that provides objective and trustworthy transportation data, recommendations, and analysis. TPA brings to offer an evidence foundation for strategic decision-making in support of an efficient transportation system. \n",
    "Gathering data from their archives, the following project is built puttiing emphasis on diifferent analysis of uses of transport throughout Sydney. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d8097c",
   "metadata": {},
   "source": [
    "# Project Goal\n",
    "**\"How the dataset can be used in analysing different aspects of transportation?\"**\n",
    "\n",
    "By providing various analysis to  the question is our following goals:\n",
    "- Explore with our chosen dataframe.\n",
    "- Take advantage of the various sources to reach an optimal conclusion that will help with either decision making/support.\n",
    "- Provide analysis that will enable us to correlate trends/patterns withreal world activities which will include:\n",
    "  - Distinction between an array of transportation rush hours\n",
    "  - In which month people travel more\n",
    "  - Analysis through outliners"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394befaf",
   "metadata": {},
   "source": [
    "# Data source\n",
    "The dataset is from the Bureau of Transport Statistics. This dataset contains NSW trains official train utilisation figures for Intercity train lines only. These figures include the data of passengers who on/tap off well as passeners who bought tickets when entering and exiting the transportation service stations. It is set out as a line and aggregated into a monthly figure for a passenger for their estimated times of travel during that month. \n",
    "The data was collected from opal train trips by month,line and card type, from July 2016 to August 2021. The format of the data set is in CSV. Here is a link to the relevant document page: https://opendata.transport.nsw.gov.au/dataset/opal-trips-train.\n",
    "\n",
    "<b>Note<b>: There were limited amount of data provided for several months in the year 2016 and 2021."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03eadc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib.pyplot import imread\n",
    "%matplotlib inline\n",
    "\n",
    "#---Linear Regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "#---naive bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "#---KMeans Clustering \n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#---feature selection\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "#---data processing\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b1d82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We tried importing the file, but this method didnâ€™t work for some reason.\n",
    "#pd.show_versions()\n",
    "#data = pd.read_csv(\"files/TrainCardType.csv\")\n",
    "# we had error opeing the file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbbd4c5",
   "metadata": {},
   "source": [
    "## Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3721ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We realised that there was an error with encoding the file. After resolving the the issue, we were able to import the file.\n",
    "# importing the file\n",
    "data = pd.read_csv(\"files/TrainCardType.csv\", encoding='utf-16',sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0182e01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show data head\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573dbaa4",
   "metadata": {},
   "source": [
    "## Cleaning the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d00767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming \n",
    "data = data.rename(columns={\"1/07/2016+C1:BA1\": \"Jul-16\"})\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f78e410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming \n",
    "data = data.rename(columns={\"Travel type\": \"Travel_type\"})\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca87d722",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the data set size \n",
    "print(\"The size of the data is : \", data.shape) \n",
    "print(\"The number of row {} and number of columns {} \".format(data.shape[0], data.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6ab44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking data type \n",
    "print(type(data))\n",
    "print(type(data['Jul-16']))\n",
    "print(type(data['Jul-16'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68aebc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show infor for data\n",
    "#data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a30c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deal with the NaN values in the data\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1778dd34",
   "metadata": {},
   "source": [
    "\n",
    "<b>Note</b>: The data set have too many null values. Dropping the null value drops almost 70% of the data. We tried dropping the value but too many rows and coulmns were droped. As a result we had to work on the dataset as it was after thorough cleaning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589971e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data =data.dropna()\n",
    "#data.shape\n",
    "#data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5605da",
   "metadata": {},
   "source": [
    "# add more, why did we decide to replace null with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02f6520",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we decide to assign 0 to null values\n",
    "data.fillna( '0', inplace = True)\n",
    "#data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d96fc2e",
   "metadata": {},
   "source": [
    "<b>Functions to remove ','"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4d622d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.replace(',','', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2bdfbb",
   "metadata": {},
   "source": [
    "<b>Changing all object into numeric values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83c6b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in data.columns[2:]:\n",
    "    data[x] = pd.to_numeric(data[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6d555b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#str to int / checking\n",
    "type(data['Jul-16'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35602c75",
   "metadata": {},
   "source": [
    "## Droping last column which will directly affect the our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c5460f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the last row Grand Total\n",
    "data_c =data.drop(247)\n",
    "data_c.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c6d932",
   "metadata": {},
   "source": [
    "## Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0444891",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_c.Route.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d82518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract all name of the Route\n",
    "data_c['Route'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9494eeb3",
   "metadata": {},
   "source": [
    "<b>There are 21 differnt train routes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e891d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_c['Travel_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b5341a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_c.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfd2168",
   "metadata": {},
   "source": [
    "##  Spliting  the data set according to years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98eea5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2016 = []\n",
    "data_2017 = []\n",
    "data_2018 = []\n",
    "data_2019 =[]\n",
    "data_2020=[]\n",
    "data_2021=[]\n",
    "for i in range(2,8):\n",
    "    data_2016.append(data_c.columns[i])\n",
    "for i in range(8,20):\n",
    "    data_2017.append(data_c.columns[i])\n",
    "for i in range(20,32):\n",
    "    data_2018.append(data_c.columns[i])\n",
    "for i in range(32,44):\n",
    "    data_2019.append(data_c.columns[i])\n",
    "for i in range(44,56):\n",
    "    data_2020.append(data_c.columns[i])\n",
    "for i in range(56,65):\n",
    "    data_2021.append(data_c.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd96344d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking \n",
    "data_2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5c1349",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_16 = data_c[data_2016]\n",
    "data_17 = data_c[data_2017]\n",
    "data_18 = data_c[data_2018]\n",
    "data_19 = data_c[data_2019]\n",
    "data_20 = data_c[data_2020]\n",
    "data_21 = data_c[data_2021]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbd4c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#total people travelled \n",
    "total16 = (data_16.sum()).sum()\n",
    "total17 = (data_17.sum()).sum()\n",
    "total18 = (data_18.sum()).sum()\n",
    "total19 = (data_19.sum()).sum()\n",
    "total20 = (data_20.sum()).sum()\n",
    "total21 = (data_21.sum()).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90a664a",
   "metadata": {},
   "source": [
    "### 2016 July to December"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3d32a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_16.sum().plot()\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Number of People Travavelled(M)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afa31a1",
   "metadata": {},
   "source": [
    "<b>Observation</b>: It can be observed here that the number of travellers increased rapidly from July to August in the year of 2016. It started to decrease drasticaly from the mid of August to mid of october. However the numbers started to increase a bit up to November and started to dicline again until december. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d3dc9a",
   "metadata": {},
   "source": [
    "### 2017 Jan to December"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e028512",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_17.sum().plot()\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Number of People Travavelled(M)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2943a879",
   "metadata": {},
   "source": [
    "<b>Observation:</b> Passengers started to ride the train in major numbers from march of 2018. The number decreased rapidly to the month of April. However the number of passengers increased more in june and immediatly decreased up to August. And carried on the same curve througout rest of the life. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6853c4d",
   "metadata": {},
   "source": [
    "### 2018 Jan to December"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f011e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_18.sum().plot()\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Number of People Travavelled(M)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beae734f",
   "metadata": {},
   "source": [
    "<b>Observation:</b> In the year 2018 the graph indicates a chevroned pattern where the number of passengers where more in the month of May. Travellers were seen less in April compared to other reduced months."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6292913",
   "metadata": {},
   "source": [
    "### 2019 Jan to December"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fce3332",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_19.sum().plot()\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Number of People Travavelled(M)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3386860b",
   "metadata": {},
   "source": [
    "<b>Observation:</b> As per other years the graphs indicated the same amount of travellers travelling in February,May,August and october. However the amount of travellers decreased from July to rest of the year compared to first six months."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2054baff",
   "metadata": {},
   "source": [
    "### 2020 Jan to December"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaafc575",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_20.sum().plot()\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Number of People Travavelled(M)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c333fb51",
   "metadata": {},
   "source": [
    "<b>Observation:</b> The year 2020 was different in regards to orevious years.It is seen the numbers were at it peak from the start of the year until March. But it decreased repidly in April and started to incline from May. It slowly increased up tp 1.7 at the end of year."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a38035e",
   "metadata": {},
   "source": [
    "### 2021 Jan to Sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f15cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_21.sum().plot()\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Number of People Travavelled(M)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39795286",
   "metadata": {},
   "source": [
    "# Hanando's work more here please add comments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8b0772",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total People Travel Over Years "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1e88e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = [total16,total17,total18,total19,total20,total21]\n",
    "years = ['2016','2017','2018','2019','2020','2021']\n",
    "color = ['r','g','b','m','y', 'b']\n",
    "plt.pie(total, labels = years, colors = color, shadow = True, startangle = 90)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc00b17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2016\n",
    "sum = data_16.sum()\n",
    "months = ['Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "color = ['r','g','b','m','y', 'b']\n",
    "plt.pie(sum, labels = months, colors = color, shadow = True, startangle = 90)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bfad4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2017\n",
    "sum = data_17.sum()\n",
    "months = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "color = ['r','g','b','m','y', 'b']\n",
    "plt.pie(sum, labels = months, colors = color, shadow = True, startangle = 90)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b90aab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2018\n",
    "sum = data_18.sum()\n",
    "months = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "color = ['r','g','b','m','y', 'b']\n",
    "plt.pie(sum, labels = months, colors = color, shadow = True, startangle = 90)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8071d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2019\n",
    "sum = data_19.sum()\n",
    "months = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "color = ['r','g','b','m','y', 'b']\n",
    "plt.pie(sum, labels = months, colors = color, shadow = True, startangle = 90)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47f61fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2020\n",
    "sum = data_20.sum()\n",
    "months = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "color = ['r','g','b','m','y', 'b']\n",
    "plt.pie(sum, labels = months, colors = color, shadow = True, startangle = 90)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed52cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2021\n",
    "sum = data_21.sum()\n",
    "months = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep']\n",
    "color = ['r','g','b','m','y', 'b']\n",
    "plt.pie(sum, labels = months, colors = color, shadow = True, startangle = 90)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6c6326",
   "metadata": {},
   "source": [
    "## add more comments here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f970656c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868e936b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9db26ad",
   "metadata": {},
   "source": [
    "# need a title "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b4414e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['2016', '2017','2018','2019','2020','2021']\n",
    "plt.figure(figsize=(15,7))\n",
    "plt.bar(\"2016\", total16, align = 'center', label = '2016') \n",
    "plt.bar( \"2017\", total17,  align = 'center', label = '2017') \n",
    "plt.bar(\"2018\", total18, color = 'red' ,align = 'center', label = '2018') \n",
    "plt.bar( \"2019\", total19,  align = 'center', label = '2019') \n",
    "plt.bar( \"2020\", total20, align = 'center', label = '2020') \n",
    "plt.bar( \"2021\", total21,  align = 'center', label = '2021') \n",
    "plt.title('Comparision for Total People Travelled over years') \n",
    "plt.ylabel('Total People Travelled(m)') \n",
    "plt.xlabel('Year') \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3147b773",
   "metadata": {},
   "source": [
    "### Observation\n",
    "\n",
    "Here different colours are used to mark every year indiviually. It can be seen that people travelled a lot in 2019 and the least in the year 2021. The numbers increase by .2 from 2017 to 2018 consecutivly less in 2016 and 2021 cause there were limited amount of data for the respectable years in the data set. However it can be assumed that the number decreased from 2020 due to global pandemic. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12e5cb2",
   "metadata": {},
   "source": [
    "# need to add comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1346fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new = pd.DataFrame({\n",
    "    'month': ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'],\n",
    "    '2016':[0,0,0,0,0,0,data_16['Jul-16'].sum(),data_16['Aug-16'].sum(),data_16['Sep-16'].sum(),data_16['Oct-16'].sum(),data_16['Nov-16'].sum(),data_16['Dec-16'].sum()],\n",
    "    '2017':[data_17['Jan-17'].sum(),data_17['Feb-17'].sum(),data_17['Mar-17'].sum(),data_17['Apr-17'].sum(),data_17['May-17'].sum(),data_17['Jun-17'].sum(),data_17['Jul-17'].sum(),data_17['Aug-17'].sum(),data_17['Sep-17'].sum(),data_17['Oct-17'].sum(),data_17['Nov-17'].sum(),data_17['Dec-17'].sum()],\n",
    "    '2018':[data_18['Jan-18'].sum(),data_18['Feb-18'].sum(),data_18['Mar-18'].sum(),data_18['Apr-18'].sum(),data_18['May-18'].sum(),data_18['Jun-18'].sum(),data_18['Jul-18'].sum(),data_18['Aug-18'].sum(),data_18['Sep-18'].sum(),data_18['Oct-18'].sum(),data_18['Nov-18'].sum(),data_18['Dec-18'].sum()],\n",
    "    '2019':[data_19['Jan-19'].sum(),data_19['Feb-19'].sum(),data_19['Mar-19'].sum(),data_19['Apr-19'].sum(),data_19['May-19'].sum(),data_19['Jun-19'].sum(),data_19['Jul-19'].sum(),data_19['Aug-19'].sum(),data_19['Sep-19'].sum(),data_19['Oct-19'].sum(),data_19['Nov-19'].sum(),data_19['Dec-19'].sum()],\n",
    "    '2020':[data_20['Jan-20'].sum(),data_20['Feb-20'].sum(),data_20['Mar-20'].sum(),data_20['Apr-20'].sum(),data_20['May-20'].sum(),data_20['Jun-20'].sum(),data_20['Jul-20'].sum(),data_20['Aug-20'].sum(),data_20['Sep-20'].sum(),data_20['Oct-20'].sum(),data_20['Nov-20'].sum(),data_20['Dec-20'].sum()],\n",
    "    '2021':[data_21['Jan-21'].sum(),data_21['Feb-21'].sum(),data_21['Mar-21'].sum(),data_21['Apr-21'].sum(),data_21['May-21'].sum(),data_21['Jun-21'].sum(),data_21['Jul-21'].sum(),data_21['Aug-21'].sum(),data_21['Sep-21'].sum(),0,0,0]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e445c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "new.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090bbc57",
   "metadata": {},
   "source": [
    "<b>Observation:</b> In the above plot it can be seen that the numbers were closely same for the years 2017 to 2019 which formed a chevroned pattern. t can be observed in 2016, here that the number of travellers increased rapidly from July and maintained the same graph for the rest of the year . Travels decreased from february to may in the year 2020 but started to incline slowly for the rest of the year. In 2021 the numbers were in the mid range until the middle of the year and started to decline for the rest of the year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4158808",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(new, columns=[\"month\", '2016','2017','2018','2019','2020','2021'])\n",
    "df2.plot.bar(figsize=(15,7));\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Number of People Travavelled(M)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3386e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.plot.barh(stacked=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5172feaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "color = {\n",
    "    \"boxes\": \"DarkGreen\",\n",
    "    \"whiskers\": \"DarkOrange\",\n",
    "    \"medians\": \"DarkBlue\",\n",
    "    \"caps\": \"Gray\",\n",
    "}\n",
    "df2.plot.box(color=color, sym=\"r+\",figsize=(15,7))\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of People Travavelled(M)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9893b255",
   "metadata": {},
   "source": [
    "# Ryan's Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b07e49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## new column to merge all trainline \n",
    "\n",
    "data['TrainLine'] = data['Route'].str[0:2] ## targets the first two string from order date \n",
    "data['TrainLine'] = data['TrainLine'].astype('object')\n",
    "data.head(25)\n",
    "\n",
    "data['TrainLine']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ce3a3a",
   "metadata": {},
   "source": [
    "## Reseting index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b514c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## reset index\n",
    "data = data.dropna()\n",
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d55c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a9ffe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2016 = data[['TrainLine','Travel_type','Jul-16','Aug-16','Sep-16','Oct-16','Nov-16','Dec-16']]\n",
    "df2017 = data[['TrainLine','Travel_type','Jan-17','Feb-17','Mar-17','Apr-17','May-17','Jun-17','Jul-17','Aug-17','Sep-17','Oct-17','Nov-17','Dec-17']]\n",
    "df2018 = data[['TrainLine','Travel_type','Jan-18','Feb-18','Mar-18','Apr-18','May-18','Jun-18','Jul-18','Aug-18','Sep-18','Oct-18','Nov-18','Dec-18']]\n",
    "df2019 = data[['TrainLine','Travel_type','Jan-19','Feb-19','Mar-19','Apr-19','May-19','Jun-19','Jul-19','Aug-19','Sep-19','Oct-19','Nov-19','Dec-19']]\n",
    "df2020 = data[['TrainLine','Travel_type','Jan-20','Feb-20','Mar-20','Apr-20','May-20','Jun-20','Jul-20','Aug-20','Sep-20','Oct-20','Nov-20','Dec-20']]\n",
    "df2021 = data[['TrainLine','Travel_type','Jan-21','Feb-21','Mar-21','Apr-21','May-21','Jun-21','Jul-21','Aug-21','Sep-21']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39bf87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## filtering adult coloumn \n",
    "adult16 = df2016[df2016.Travel_type == 'Adult']\n",
    "adult17 = df2017[df2017.Travel_type == 'Adult']\n",
    "adult18 = df2018[df2018.Travel_type == 'Adult']\n",
    "adult19 = df2019[df2019.Travel_type == 'Adult']\n",
    "adult20 = df2020[df2020.Travel_type == 'Adult']\n",
    "adult21 = df2021[df2021.Travel_type == 'Adult']\n",
    "\n",
    "Concession16 = df2016[df2016.Travel_type == 'Concession']\n",
    "Concession17 = df2017[df2017.Travel_type == 'Concession']\n",
    "Concession18 = df2018[df2018.Travel_type == 'Concession']\n",
    "Concession19 = df2019[df2019.Travel_type == 'Concession']\n",
    "Concession20 = df2020[df2020.Travel_type == 'Concession']\n",
    "Concession21 = df2021[df2021.Travel_type == 'Concession']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5118aa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "## group by the trainline and travel type \n",
    "adult16 = adult16.groupby(['Travel_type','TrainLine'])\n",
    "adult17 = adult17.groupby(['Travel_type','TrainLine'])\n",
    "adult18 = adult18.groupby(['Travel_type','TrainLine'])\n",
    "adult19 = adult19.groupby(['Travel_type','TrainLine'])\n",
    "adult20 = adult20.groupby(['Travel_type','TrainLine'])\n",
    "adult21 = adult21.groupby(['Travel_type','TrainLine'])\n",
    "\n",
    "Concession16 = Concession16.groupby(['Travel_type','TrainLine'])\n",
    "Concession17 = Concession17.groupby(['Travel_type','TrainLine'])\n",
    "Concession18 = Concession18.groupby(['Travel_type','TrainLine'])\n",
    "Concession19 = Concession19.groupby(['Travel_type','TrainLine'])\n",
    "Concession20 = Concession20.groupby(['Travel_type','TrainLine'])\n",
    "Concession21 = Concession21.groupby(['Travel_type','TrainLine'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76574a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## multiple row Referring to the same trainline "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2309c675",
   "metadata": {},
   "source": [
    "## Final sum of the tables yearly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d7e957",
   "metadata": {},
   "outputs": [],
   "source": [
    "sumadult16 = adult16.sum()\n",
    "sumadult17 = adult17.sum()\n",
    "sumadult18 = adult18.sum()\n",
    "sumadult19 = adult19.sum()\n",
    "sumadult20 = adult20.sum()\n",
    "sumadult21 = adult21.sum()\n",
    "\n",
    "sumConcession16 = Concession16.sum()\n",
    "sumConcession17 = Concession17.sum()\n",
    "sumConcession18 = Concession18.sum()\n",
    "sumConcession19 = Concession19.sum()\n",
    "sumConcession20 = Concession20.sum()\n",
    "sumConcession21 = Concession21.sum()\n",
    "\n",
    "## final table that has the total adult table with yearly total "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f1426e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sumadult21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca584ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "sumConcession21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1a5c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2016 = df2016.groupby(['TrainLine','Travel_type'])\n",
    "# df2017 = df2017.groupby(['TrainLine','Travel_type'])\n",
    "# df2018 = df2018.groupby(['TrainLine','Travel_type'])\n",
    "# df2019 = df2019.groupby(['TrainLine','Travel_type'])\n",
    "# df2020 = df2020.groupby(['TrainLine','Travel_type'])\n",
    "# df2021 = df2021.groupby(['TrainLine','Travel_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136753ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = sumConcession20.plot(kind='bar',figsize=(15,8), title=\"Total Attendance of Concession Opal Travel 2020\")\n",
    "\n",
    "plot.set_xlabel(\"TrainLines from Concession Opal Attendance\")\n",
    "plot.set_ylabel(\"Number of Travels (100k)\")\n",
    "plot.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be912682",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = sumadult20.plot(kind='bar',figsize=(15,8), title=\"Total Attendance of Adult Opal Travel 2020\")\n",
    "\n",
    "plot.set_xlabel(\"TrainLines from Adult Opal Attendance\")\n",
    "plot.set_ylabel(\"Number of Travels in 100k\")\n",
    "plot.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca09049",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = sumConcession21.plot(kind='bar',figsize=(15,8), title=\"Total Attendance of Concession Opal Travel 2021\",)\n",
    "plot.set_xlabel(\"TrainLines from Concession Opal Attendance\")\n",
    "plot.set_ylabel(\"Number of Travels (100k)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cf36d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = sumadult21.plot(kind='bar',figsize=(15,8), title=\"Total Attendance of Adult Opal Travel 2021\")\n",
    "\n",
    "plot.set_xlabel(\"TrainLines from Adult Opal Attendance\")\n",
    "plot.set_ylabel(\"Number of Travels in 100k\")\n",
    "plot.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251536d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum2016 = adult16.sum()\n",
    "sum2017 = adult17.sum()\n",
    "sum2018 = adult18.sum()\n",
    "sum2019 = adult19.sum()\n",
    "sum2020 = adult20.sum()\n",
    "sum2021 = adult21.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec89c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37f1f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create separate dataframes\n",
    "## add total column \n",
    "sumadult16['TotalCountbyTrainLine'] = sumadult16['Jul-16'] + sumadult16['Aug-16'] + sumadult16['Sep-16'] + sumadult16['Oct-16'] + sumadult16['Nov-16'] + sumadult16['Dec-16'] \n",
    "sumadult17['TotalCountbyTrainLine'] = sumadult17['Jan-17'] + sumadult17['Feb-17'] + sumadult17['Mar-17'] + sumadult17['Apr-17'] + sumadult17['May-17'] + sumadult17['Jun-17'] + sumadult17['Jul-17'] + sumadult17['Aug-17'] + sumadult17['Sep-17'] + sumadult17['Oct-17'] + sumadult17['Nov-17'] + sumadult17['Dec-17'] \n",
    "sumadult18['TotalCountbyTrainLine'] = sumadult18['Jan-18'] + sumadult18['Feb-18'] + sumadult18['Mar-18'] + sumadult18['Apr-18'] + sumadult18['May-18'] + sumadult18['Jun-18'] + sumadult18['Jul-18'] + sumadult18['Aug-18'] + sumadult18['Sep-18'] + sumadult18['Oct-18'] + sumadult18['Nov-18'] + sumadult18['Dec-18'] \n",
    "sumadult19['TotalCountbyTrainLine'] = sumadult19['Jan-19'] + sumadult19['Feb-19'] + sumadult19['Mar-19'] + sumadult19['Apr-19'] + sumadult19['May-19'] + sumadult19['Jun-19'] + sumadult19['Jul-19'] + sumadult19['Aug-19'] + sumadult19['Sep-19'] + sumadult19['Oct-19'] + sumadult19['Nov-19'] + sumadult19['Dec-19'] \n",
    "sumadult20['TotalCountbyTrainLine'] = sumadult20['Jan-20'] + sumadult20['Feb-20'] + sumadult20['Mar-20'] + sumadult20['Apr-20'] + sumadult20['May-20'] + sumadult20['Jun-20'] + sumadult20['Jul-20'] + sumadult20['Aug-20'] + sumadult20['Sep-20'] + sumadult20['Oct-20'] + sumadult20['Nov-20'] + sumadult20['Dec-20'] \n",
    "sumadult21['TotalCountbyTrainLine'] = sumadult21['Jan-21'] + sumadult21['Feb-21'] + sumadult21['Mar-21'] + sumadult21['Apr-21'] + sumadult21['May-21'] + sumadult21['Jun-21'] + sumadult21['Jul-21'] + sumadult21['Aug-21'] + sumadult21['Sep-21'] \n",
    "#sumadult20['TotalCountbyTrainLine'] = sumadult20['TotalCountbyTrainLine'].astype('int32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064bbecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sumadult21"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f27bd0",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f98ef15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initalise train and test variable \n",
    "train, test = train_test_split(data, test_size = 0.2, random_state=142)\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb870e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = linear_model.LinearRegression()\n",
    "X_train = train[['Dec-18', 'Dec-19']]\n",
    "y_train = train['Dec-20']\n",
    "X_test = test[['Dec-18', 'Dec-19']]\n",
    "y_test = test['Dec-20']\n",
    "reg.fit(X_train, y_train)\n",
    "print(\"y = x *\", reg.coef_, \"+\", reg.intercept_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63960d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = reg.predict(X_test)\n",
    "mse = ((np.array(y_test)-predicted)**2).sum()/len(y_test)\n",
    "r2 = r2_score(y_test, predicted)\n",
    "print(\"MSE:\", mse) ##mean square error if it's too low means its good\n",
    "print(\"R Squared:\", r2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a271212c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = reg.predict(X_test)\n",
    "mse = ((np.array(y_test)-predicted)**2).sum()/len(y_test)\n",
    "r2 = r2_score(y_test, predicted)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"R Squared:\", r2) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b5069a",
   "metadata": {},
   "source": [
    "## Hanndo's regression model but he used other columns\n",
    "## please write another observation that includes the relationship between the alternative x and y variable and delete this column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd83cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccc9669",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [['2016', total16],['2017', total17],['2018', total18],['2019', total19],['2020', total20],['2021', total21],]\n",
    "df = pd.DataFrame(lst, columns = ['Year', 'Usage'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3687ac80",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size = 0.2, random_state=142)\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e4d11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train[['Year']]\n",
    "y_train = train['Usage']\n",
    "\n",
    "x_test = test[['Year']]\n",
    "y_test = test['Usage']\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaa55d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = linear_model.LinearRegression()\n",
    "lr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82661be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6df475",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e20ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_lr = mean_squared_error(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48301c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b325bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x,y, color='blue')\n",
    "plt.plot([0,2025],[b,m*100+b],'r')\n",
    "plt.title('Ticket use over time', fontsize = 20)\n",
    "plt.xlabel('Year', fontsize = 15)\n",
    "plt.ylabel('Usage', fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a254cef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y_df=pd.DataFrame({'Actual Value': y_test, 'Predicted Value': y_pred, 'Difference': y_test - y_pred})\n",
    "pred_y_df[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41b71fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "###I think 3 is done? Regression is hella sus above^ will need 2 fix later "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37629044",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d758e79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_l =data_l =data_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de24c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(data_l['Aug-21'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5baf417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changeing strings to intiger value \n",
    "def get_categorical_col(df):\n",
    "    s = (data_l.dtypes == 'object')\n",
    "    cols = list(s[s].index)\n",
    "    return cols\n",
    "print(\"categorical columns in data:\",get_categorical_col(data_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6019e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling the function GET \n",
    "def enc(data_l):\n",
    "    lab_enc=LabelEncoder()\n",
    "    #onehot_enc=OneHotEncoder(drop='first', sparse=False)\n",
    "    data_l['Route'] = lab_enc.fit_transform(data_l['Route'])\n",
    "    data_l['Travel_type'] = lab_enc.fit_transform(data_l['Travel_type'])\n",
    "\n",
    "enc(data_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388a913b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e060459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split your data into training(80%) and testing data (20%) and use random_state=42\n",
    "train, test = train_test_split(data_l, test_size=0.2, random_state=42)\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e270ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression model\n",
    "# Getting input data and targets for building prediction model\n",
    "X_train =train.drop(['Aug-21'],axis=1)\n",
    "y_train = train['Aug-21']\n",
    "X_test =test.drop(['Aug-21'],axis=1)\n",
    "y_test=test['Aug-21']\n",
    "\n",
    "print(X_train.shape,\"train x\")\n",
    "print(y_train.shape,\"train y\")\n",
    "print(X_test.shape, \"test x\")\n",
    "print(y_test.shape, \"test y\")\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129ddbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf78a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69a5986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do predictions on test set\n",
    "# Doing predictions on train and test set\n",
    "y_test_pred=model.predict(X_test)\n",
    "y_train_pred = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1801ef56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the performance of your trained model\n",
    "print(\"Accuracy score on training set: \", accuracy_score(y_train, y_train_pred))\n",
    "print(\"Accuracy score on testing set: \", accuracy_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cee75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking confusion matrix\n",
    "print(\"Confusion matrix on test set: \")\n",
    "print(confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef799eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# future modification / relationship\n",
    "corrmat = X_train.corr()\n",
    "top_corr_features = corrmat.index\n",
    "plt.figure(figsize=(20,10))\n",
    "g=sns.heatmap(X_train[top_corr_features].corr(), annot=True, cmap=\"RdYlGn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee2986e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating RFE object\n",
    "lr_model=LogisticRegression()\n",
    "rfe= RFE(estimator=lr_model, n_features_to_select=5, step=1)\n",
    "rfe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae098b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doing evaluation\n",
    "y_test_hat = rfe.predict(X_test)\n",
    "print(\"accuracy score on test set: \", accuracy_score(y_test, y_test_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde9e31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize all features\n",
    "for i in range(X_train.shape[1]):\n",
    "    print('Column: %d, Selected %s, Rank: %.3f' % (i, rfe.support_[i], rfe.ranking_[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8581d281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to increment number of features, one at each time\n",
    "acc_scores = []\n",
    "for i in range(1,64):\n",
    "    clf = LogisticRegression()\n",
    "    rfe = RFE(estimator=clf, n_features_to_select=i)\n",
    "    # training model\n",
    "    rfe.fit(X_train, y_train)\n",
    "    # predicting on test set\n",
    "    y_pred = rfe.predict(X_test)\n",
    "    acc_score = accuracy_score(y_test, y_pred)\n",
    "    # print this\n",
    "    print(\"Acc on test set using\", i, \"features: \", acc_score)\n",
    "    # append to the list\n",
    "    acc_scores.append(acc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c8aa36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimating accuracy score on test set using RFE by using different number of features\n",
    "estimator = LogisticRegression()\n",
    "acc_scores = []\n",
    "for i in range(1, 64):\n",
    "    selector = RFE(estimator, i)\n",
    "    selector = selector.fit(X_train, y_train)\n",
    "    supp = selector.get_support()\n",
    "\n",
    "    predicted = selector.predict(X_test)\n",
    "    acc_score = accuracy_score(y_test, predicted)\n",
    "    acc_scores.append(acc_score)\n",
    "  \n",
    "best = 1\n",
    "for item in acc_scores:\n",
    "    if item < acc_scores[best - 1]:\n",
    "        best = acc_scores.index(item) + 1\n",
    "\n",
    "plt.grid()   \n",
    "plt.xlabel('# No. of features')\n",
    "plt.ylabel('Accuracy score on test set')\n",
    "plt.plot(range(1, 64), acc_scores, marker = 'o', color = 'lightblue', markeredgewidth = 1 ,markeredgecolor = 'lightblue', markerfacecolor = 'None')\n",
    "plt.plot(best, acc_scores[best-1], marker = 'o', markerfacecolor = 'lightblue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8bbff2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffcbfe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221574e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81afd708",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e10545cb",
   "metadata": {},
   "source": [
    "## Observations\n",
    "-  There are no apparent curves in the plots which means the model is linear in the parameters and its residuals.\n",
    "-  The process of obtaining one observation does not affect the process of obtaining the next observations (independence).\n",
    "-  Why the r square is close to 1, the model is bias and we cannot rely on a regression to predict future outcome by past records\n",
    "\n",
    "\n",
    "### Multinomial naive bayes will be implemented below in order to see if it can predict past records."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7aebf3",
   "metadata": {},
   "source": [
    "# check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "38df9468",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---creating a new dataframe with the relevant datasets\n",
    "dftest = data[['Dec-18','Dec-19','Dec-20']]\n",
    "\n",
    "#---dropping null values and resetting the index\n",
    "dftest = dftest.dropna()\n",
    "dftest = dftest.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bfb959",
   "metadata": {},
   "source": [
    "# Performing a multinomial naive bayes analysis on the data\n",
    "\n",
    "we wil  create a naive bayes analysis function to allow us to perform the analysis in a modular manner below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ff8f32b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial: 0.058133333333333335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryanlam/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#---performing a multinomial naive bayes analysis on the data\n",
    "clf = MultinomialNB()\n",
    "data = dftest[['Dec-18','Dec-19']]\n",
    "target = dftest[['Dec-20']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, train_size = 0.70, random_state=0)\n",
    "\n",
    "y_train=y_train.values\n",
    "clf.fit (X_train, y_train)\n",
    "\n",
    "y_test=y_test.values\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Multinomial:\", np.mean(y_pred==y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259062eb",
   "metadata": {},
   "source": [
    "The results from the naive bayes analysis -- similar to the linear regression -- are poor in the context of the data, though there is some level of prediction to be made. What this means is that past records from previous year can change due to external circumstances. for example, due to the covid pandemic, the sum of train attendance has staggared in comparison to previous years\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8bdb502b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated probability of classess: \n",
      " [0.30057803 0.01734104 0.00578035 0.00578035 0.00578035 0.00578035\n",
      " 0.00578035 0.01156069 0.00578035 0.00578035 0.00578035 0.00578035\n",
      " 0.00578035 0.00578035 0.00578035 0.00578035 0.00578035 0.00578035\n",
      " 0.00578035 0.00578035 0.00578035 0.00578035 0.00578035 0.00578035\n",
      " 0.00578035 0.00578035 0.00578035 0.00578035 0.00578035 0.00578035\n",
      " 0.00578035 0.00578035 0.00578035 0.00578035 0.00578035 0.00578035\n",
      " 0.00578035 0.00578035 0.00578035 0.00578035 0.00578035 0.00578035\n",
      " 0.00578035 0.00578035 0.00578035 0.00578035 0.00578035 0.00578035\n",
      " 0.00578035 0.00578035 0.00578035 0.00578035 0.00578035 0.00578035\n",
      " 0.00578035 0.00578035 0.00578035 0.00578035 0.00578035 0.00578035\n",
      " 0.00578035 0.00578035 0.00578035 0.00578035 0.00578035 0.00578035\n",
      " 0.00578035 0.00578035 0.00578035 0.00578035 0.00578035 0.00578035\n",
      " 0.00578035 0.00578035 0.00578035 0.00578035 0.00578035 0.00578035\n",
      " 0.00578035 0.00578035 0.00578035 0.00578035 0.00578035 0.00578035\n",
      " 0.00578035 0.00578035 0.00578035 0.00578035 0.00578035 0.00578035\n",
      " 0.00578035 0.00578035 0.00578035 0.00578035 0.00578035 0.00578035\n",
      " 0.00578035 0.00578035 0.00578035 0.00578035 0.00578035 0.00578035\n",
      " 0.00578035 0.00578035 0.00578035 0.00578035 0.00578035 0.00578035\n",
      " 0.00578035 0.00578035 0.00578035 0.00578035 0.00578035 0.00578035\n",
      " 0.00578035 0.00578035 0.00578035 0.00578035 0.00578035]\n",
      "Estimated class-conditional probabilities for each feature: \n",
      " [[9.84807215e-01 1.51927847e-02]\n",
      " [6.66666667e-02 9.33333333e-01]\n",
      " [1.06060606e-01 8.93939394e-01]\n",
      " [1.42857143e-01 8.57142857e-01]\n",
      " [5.00000000e-01 5.00000000e-01]\n",
      " [4.81481481e-01 5.18518519e-01]\n",
      " [2.69230769e-01 7.30769231e-01]\n",
      " [4.06779661e-01 5.93220339e-01]\n",
      " [5.00000000e-01 5.00000000e-01]\n",
      " [5.25641026e-01 4.74358974e-01]\n",
      " [3.50000000e-01 6.50000000e-01]\n",
      " [2.27544910e-01 7.72455090e-01]\n",
      " [5.42750929e-01 4.57249071e-01]\n",
      " [2.28070175e-01 7.71929825e-01]\n",
      " [6.17554859e-01 3.82445141e-01]\n",
      " [3.80281690e-01 6.19718310e-01]\n",
      " [6.26690182e-01 3.73309818e-01]\n",
      " [3.05785124e-01 6.94214876e-01]\n",
      " [6.43948296e-01 3.56051704e-01]\n",
      " [6.29156010e-01 3.70843990e-01]\n",
      " [4.94117647e-01 5.05882353e-01]\n",
      " [6.50326797e-01 3.49673203e-01]\n",
      " [5.45189504e-01 4.54810496e-01]\n",
      " [5.72084481e-01 4.27915519e-01]\n",
      " [5.00000000e-01 5.00000000e-01]\n",
      " [6.57917261e-01 3.42082739e-01]\n",
      " [5.00000000e-01 5.00000000e-01]\n",
      " [4.79425212e-01 5.20574788e-01]\n",
      " [8.73362445e-04 9.99126638e-01]\n",
      " [4.71754583e-01 5.28245417e-01]\n",
      " [4.75901175e-01 5.24098825e-01]\n",
      " [4.86792453e-01 5.13207547e-01]\n",
      " [5.56614045e-01 4.43385955e-01]\n",
      " [5.97728631e-04 9.99402271e-01]\n",
      " [5.92340951e-01 4.07659049e-01]\n",
      " [6.31100674e-01 3.68899326e-01]\n",
      " [5.47561813e-01 4.52438187e-01]\n",
      " [2.06868018e-04 9.99793132e-01]\n",
      " [4.94851099e-01 5.05148901e-01]\n",
      " [4.59440880e-01 5.40559120e-01]\n",
      " [5.71690895e-01 4.28309105e-01]\n",
      " [4.55025338e-01 5.44974662e-01]\n",
      " [5.36038693e-01 4.63961307e-01]\n",
      " [6.25688870e-01 3.74311130e-01]\n",
      " [5.00000000e-01 5.00000000e-01]\n",
      " [4.60874408e-01 5.39125592e-01]\n",
      " [4.92084433e-01 5.07915567e-01]\n",
      " [5.21082699e-01 4.78917301e-01]\n",
      " [4.98515341e-01 5.01484659e-01]\n",
      " [6.70615183e-01 3.29384817e-01]\n",
      " [5.30068027e-01 4.69931973e-01]\n",
      " [6.12138753e-01 3.87861247e-01]\n",
      " [5.51473237e-01 4.48526763e-01]\n",
      " [5.74000068e-01 4.25999932e-01]\n",
      " [4.90262403e-01 5.09737597e-01]\n",
      " [4.74646983e-01 5.25353017e-01]\n",
      " [5.16808847e-01 4.83191153e-01]\n",
      " [5.23267974e-01 4.76732026e-01]\n",
      " [5.72658160e-01 4.27341840e-01]\n",
      " [5.95658039e-01 4.04341961e-01]\n",
      " [1.31725676e-01 8.68274324e-01]\n",
      " [4.96766550e-01 5.03233450e-01]\n",
      " [4.94896200e-01 5.05103800e-01]\n",
      " [5.21265582e-01 4.78734418e-01]\n",
      " [4.74581243e-01 5.25418757e-01]\n",
      " [5.11870590e-01 4.88129410e-01]\n",
      " [5.50762337e-01 4.49237663e-01]\n",
      " [5.63918757e-01 4.36081243e-01]\n",
      " [4.76379526e-01 5.23620474e-01]\n",
      " [5.26690790e-01 4.73309210e-01]\n",
      " [4.94228344e-01 5.05771656e-01]\n",
      " [5.46547862e-01 4.53452138e-01]\n",
      " [5.38513093e-01 4.61486907e-01]\n",
      " [5.13417887e-01 4.86582113e-01]\n",
      " [4.80020704e-01 5.19979296e-01]\n",
      " [5.49090808e-01 4.50909192e-01]\n",
      " [4.96918439e-01 5.03081561e-01]\n",
      " [5.00374867e-01 4.99625133e-01]\n",
      " [2.44265859e-05 9.99975573e-01]\n",
      " [5.23523488e-01 4.76476512e-01]\n",
      " [5.13259795e-01 4.86740205e-01]\n",
      " [4.78748486e-01 5.21251514e-01]\n",
      " [4.77023756e-01 5.22976244e-01]\n",
      " [4.49654821e-01 5.50345179e-01]\n",
      " [5.45383423e-01 4.54616577e-01]\n",
      " [5.07842891e-01 4.92157109e-01]\n",
      " [5.03349558e-01 4.96650442e-01]\n",
      " [1.17582043e-05 9.99988242e-01]\n",
      " [1.03806007e-01 8.96193993e-01]\n",
      " [5.39651111e-01 4.60348889e-01]\n",
      " [5.23229592e-01 4.76770408e-01]\n",
      " [1.29917886e-01 8.70082114e-01]\n",
      " [1.00988679e-05 9.99989901e-01]\n",
      " [4.71756920e-01 5.28243080e-01]\n",
      " [4.65183213e-01 5.34816787e-01]\n",
      " [1.16915216e-01 8.83084784e-01]\n",
      " [4.94275750e-01 5.05724250e-01]\n",
      " [4.89594561e-01 5.10405439e-01]\n",
      " [4.83969270e-01 5.16030730e-01]\n",
      " [4.94825859e-01 5.05174141e-01]\n",
      " [5.07136357e-01 4.92863643e-01]\n",
      " [5.44105165e-06 9.99994559e-01]\n",
      " [5.06467017e-01 4.93532983e-01]\n",
      " [1.05045546e-01 8.94954454e-01]\n",
      " [5.02129041e-01 4.97870959e-01]\n",
      " [4.80631714e-01 5.19368286e-01]\n",
      " [5.14210675e-01 4.85789325e-01]\n",
      " [4.78428262e-01 5.21571738e-01]\n",
      " [5.68339072e-01 4.31660928e-01]\n",
      " [1.38430367e-01 8.61569633e-01]\n",
      " [1.20874368e-01 8.79125632e-01]\n",
      " [4.81472916e-01 5.18527084e-01]\n",
      " [5.42850607e-01 4.57149393e-01]\n",
      " [1.24274305e-01 8.75725695e-01]\n",
      " [4.94828625e-01 5.05171375e-01]\n",
      " [5.35744265e-01 4.64255735e-01]\n",
      " [5.05712932e-01 4.94287068e-01]\n",
      " [5.09451982e-01 4.90548018e-01]\n",
      " [5.27943719e-01 4.72056281e-01]]\n"
     ]
    }
   ],
   "source": [
    "# Explore the learned model parameters (probabilities)\n",
    "# Note that the probabilities are in the logorithmic form. Why? The log-sum-exp trick for underflow of probability products\n",
    "print('Estimated probability of classess: \\n', np.e**clf.class_log_prior_)\n",
    "print('Estimated class-conditional probabilities for each feature: \\n', np.e**clf.feature_log_prob_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892fce3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be0cb23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d56970",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b5ce6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa057a1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5081c9c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485153fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "387cff47",
   "metadata": {},
   "source": [
    "# i dint put my prediction model here makeing some few changes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64caf8ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb81438",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
